{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import VGG16, Xception, InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_for_class(data, class_id, figsize=(10,7)):\n",
    "    \"\"\"\n",
    "    Plots the distribution of the predictions given a label\n",
    "    \"\"\"\n",
    "    subset = data[data[\"Labels\"] == class_id]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(\"Count per Predicted Label\")\n",
    "    plt.xlabel(\"Food Item\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    value_counts = subset[\"Predictions\"].value_counts().plot(kind=\"bar\")\n",
    "    return value_counts\n",
    "\n",
    "def get_most_accurate(data, k=1):\n",
    "    \"\"\"\n",
    "    Returns top k most accurate predictions\n",
    "    \"\"\"\n",
    "    subset = data[data[\"Labels\"]==data[\"Predictions\"]]\n",
    "    results = (subset[\"Labels\"].value_counts()/data[\"Labels\"].value_counts()).sort_values(ascending=False)[:k]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shape = (200, 200)\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2, # randomly shift images vertically (fraction of total height)\n",
    "    rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.05, # randomly zoom image\n",
    "    brightness_range=[0.4, 0.8],\n",
    "    fill_mode=\"reflect\"\n",
    "    ) \n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=\"../images/train\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=\"../images/valid\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory=\"../images/test\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "STEP_SIZE_TRAIN=np.ceil(train_generator.n/train_generator.batch_size)\n",
    "STEP_SIZE_VALID=np.ceil(valid_generator.n/valid_generator.batch_size)\n",
    "STEP_SIZE_TEST=np.ceil(test_generator.n/test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(os.path.join(\"keras_models\", \"model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), verbose=1, \n",
    "                             monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit base model\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=[earlyStopping, checkpoint, reduce_lr_loss],\n",
    "                    epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base VGG16\n",
    "base_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(shape[0], shape[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last few layers\n",
    "top_block = base_vgg16.output\n",
    "\n",
    "top_block = GlobalAveragePooling2D()(top_block) # pool over height/width to reduce number of parameters\n",
    "top_block = Dense(256, activation='relu')(top_block) # add a Dense layer\n",
    "predictions = Dense(num_classes, activation='softmax')(top_block) # add another Dense layer\n",
    "vgg_transfer = Model(inputs=base_vgg16.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "vgg_transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.0001),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "checkpoint = ModelCheckpoint(os.path.join(\"keras_models\", \"model-vgg16-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_vgg = vgg_transfer.fit_generator(generator=train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[earlyStopping, checkpoint],\n",
    "                                       epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last few layers\n",
    "for i, layer in enumerate(reversed(vgg_transfer.layers)):\n",
    "    layer.trainable = True\n",
    "    if i > 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "vgg_transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=SGD(lr=0.0001), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue to fit model\n",
    "history_vgg = vgg_transfer.fit_generator(generator=train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[earlyStopping, checkpoint],\n",
    "                                       epochs=100, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
