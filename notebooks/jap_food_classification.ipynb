{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import VGG16, Xception, InceptionV3, MobileNet, ResNet50\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_for_class(data, class_id, figsize=(10,7)):\n",
    "    \"\"\"\n",
    "    Plots the distribution of the predictions given a label\n",
    "    \"\"\"\n",
    "    subset = data[data[\"Labels\"] == class_id]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(\"Count per Predicted Label\")\n",
    "    plt.xlabel(\"Food Item\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    value_counts = subset[\"Predictions\"].value_counts().plot(kind=\"bar\")\n",
    "    return value_counts\n",
    "\n",
    "def get_most_accurate(data, k=1):\n",
    "    \"\"\"\n",
    "    Returns top k most accurate predictions\n",
    "    \"\"\"\n",
    "    subset = data[data[\"Labels\"]==data[\"Predictions\"]]\n",
    "    results = (subset[\"Labels\"].value_counts()/data[\"Labels\"].value_counts()).sort_values(ascending=False)[:k]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Image Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shape = (200, 200)\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2, # randomly shift images vertically (fraction of total height)\n",
    "    rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.05, # randomly zoom image\n",
    "    brightness_range=[0.4, 0.8],\n",
    "    fill_mode=\"reflect\"\n",
    "    ) \n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=\"../images/train\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=\"../images/valid\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    seed=2019)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory=\"../images/test\",\n",
    "    target_size=shape,\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "# create step size\n",
    "STEP_SIZE_TRAIN=np.ceil(train_generator.n/train_generator.batch_size)\n",
    "STEP_SIZE_VALID=np.ceil(valid_generator.n/valid_generator.batch_size)\n",
    "STEP_SIZE_TEST=np.ceil(test_generator.n/test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(shape[0], shape[1], 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=l2(1e-4)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "earlyStopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(os.path.join(\"..\", \"models\", \"model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), verbose=1, \n",
    "                             monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit base model\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=[earlyStopping, checkpoint, reduce_lr_loss],\n",
    "                    epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base MobileNet\n",
    "base_mn = MobileNet(weights='imagenet', include_top=False, input_shape=(shape[0], shape[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last few layers\n",
    "top_block = base_mn.output\n",
    "\n",
    "top_block = GlobalAveragePooling2D()(top_block) # pool over height/width to reduce number of parameters\n",
    "top_block = Dense(256, activation='relu')(top_block) # add a Dense layer\n",
    "predictions = Dense(num_classes, activation='softmax')(top_block) # add another Dense layer\n",
    "mn_transfer = Model(inputs=base_mn.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze last few layers\n",
    "for i, layer in enumerate(reversed(mn_transfer.layers)):\n",
    "    layer.trainable = True\n",
    "    if i > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mn_transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.0002),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "checkpoint3 = ModelCheckpoint(os.path.join(\"..\",\"keras_models\", \"model-mobilenet-RMSprop0.0002-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_mn = mn_transfer.fit_generator(generator=train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[earlyStopping, checkpoint3],\n",
    "                                       epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "transfer = load_model(os.path.join(\"..\", \"keras_models\", \"model-mobilenet-RMSprop0.0002-002-0.509663-0.484030.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "transfer.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=RMSprop(lr=0.0001), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue fitting\n",
    "checkpoint3 = ModelCheckpoint(os.path.join(\"..\", \"keras_models\", \"model-mobilenet-RMSprop0.0002to0.0001-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5\"), \n",
    "                              verbose=1, monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\n",
    "history_mn = transfer.fit_generator(generator=train_generator,\n",
    "                                       steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=STEP_SIZE_VALID,\n",
    "                                       callbacks=[earlyStopping, checkpoint3],\n",
    "                                       epochs=100, verbose=1, initial_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "val_loss, val_acc = transfer.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID, verbose=1)\n",
    "print(\"Val Loss: {} \\nVal Accuracy: {}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test images\n",
    "test_generator.reset()\n",
    "pred = transfer.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean predictions\n",
    "predictions = pred.argmax(axis=-1)\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predicted_labels = [labels[k] for k in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction dataframe\n",
    "filenames = test_generator.filenames\n",
    "correct_labels = [filename[:filename.find(\"\\\\\")] for filename in filenames]\n",
    "results = pd.DataFrame({\"Filename\": filenames, \"Labels\": correct_labels, \"Predictions\": predicted_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_accurate(results, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_for_class(results, \"Kuromame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 1 image\n",
    "source = \"valid\"\n",
    "random_folder = np.random.choice(os.listdir(os.path.join(\"..\", \"images\", source)))\n",
    "random_image = np.random.choice(os.listdir(os.path.join(\"..\", \"images\", source, random_folder)))\n",
    "img = image.load_img(os.path.join(\"..\", \"images\", source, random_folder, random_image), target_size = (shape[0], shape[1]))\n",
    "plt.imshow(img)\n",
    "img = image.img_to_array(img) / 255\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "print(\"Actual:\", random_image)\n",
    "print(\"Predicted:\", labels[best_model.predict(img).argmax(axis=-1)[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
